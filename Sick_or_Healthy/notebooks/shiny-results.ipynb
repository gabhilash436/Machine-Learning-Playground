{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically show plots inside the notebook\n",
    "%matplotlib inline  \n",
    "\n",
    "# reload all modules before executing code\n",
    "%load_ext autoreload\n",
    "%autoreload 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will use this notebook as a basis to walk us through what you did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 688)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import independent features  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "features = pd.read_csv('../data/features.csv')\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 688 independent features for 288 patients. However, it is quiet possible that many of these features are redundant. Therefore, I employ exploratory data analysis namely univariate and bivariate analysis to eliminate redundant features.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 237)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bivariate analysis\n",
    "corr_matrix = features.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "features = features.drop(features[to_drop], axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, more than half of features had a correlation of more than 90% with other features. One can adjust correlation threshold on a need basis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 171)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# univariate analysis \n",
    "X = features.iloc[:, 1:].values\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "vt = VarianceThreshold(0.2)\n",
    "X = vt.fit_transform(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With univariate analysis, I try to remove those features which have variance below 0.2 . Reason being, features with lesser variance will not be able to distinguish the data effectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import labels - 1-sick or 0-healthy\n",
    "from matplotlib import pyplot as plt \n",
    "labels = pd.read_csv('../data/labels.csv')\n",
    "y = labels.iloc[:, 1].values\n",
    "x_1 = [0,1]\n",
    "x_2 = [y.size - np.count_nonzero(y), np.count_nonzero(y)]\n",
    "plt.figure(1)\n",
    "plt.bar(x_1, x_2,width=0.15, align = 'center') \n",
    "plt.title('Distribution of original labels') \n",
    "plt.ylabel('Number of Patients') \n",
    "plt.xlabel('Sickness status')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of labels is skewed towards helathy patients. Number of healthy patients is more than double the size of sick patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling is an important preprocessing step since we do not wish to see one feature influencing the result more than the others. Feature scaling essentially standardizes features by removing the mean and scaling to unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9088261438680943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 50)\n",
    "X = pca.fit_transform(X)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(sum(explained_variance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a feature extraction technique. It is a unsupervised, generates topN eigen vectors with a highest variance. I selected top 50 features that account for 90% of the variance. Instead of using 688 features with 100% variance, I rather choose small subset of features to account for lesser variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# create ANN model \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dropout(0.3, input_shape = (50,)))\n",
    "classifier.add(Dense(21,  activation='relu', kernel_initializer = 'uniform'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(21, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANN has been used for binary classification task in here. It is a sequential model with 2 hidden layers and 3 regularization layers. DropOut layer reduces overfitting in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "288/288 [==============================] - 0s 1ms/step - loss: 0.6881 - acc: 0.7535\n",
      "Epoch 2/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.6721 - acc: 0.7604\n",
      "Epoch 3/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.6446 - acc: 0.7604\n",
      "Epoch 4/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.5722 - acc: 0.7604\n",
      "Epoch 5/500\n",
      "288/288 [==============================] - 0s 163us/step - loss: 0.5086 - acc: 0.7604\n",
      "Epoch 6/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.4986 - acc: 0.7604\n",
      "Epoch 7/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.4745 - acc: 0.7604\n",
      "Epoch 8/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.4677 - acc: 0.7604\n",
      "Epoch 9/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.4932 - acc: 0.7604\n",
      "Epoch 10/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.4518 - acc: 0.7604\n",
      "Epoch 11/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.4549 - acc: 0.7604\n",
      "Epoch 12/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.4548 - acc: 0.7708\n",
      "Epoch 13/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.4443 - acc: 0.7708\n",
      "Epoch 14/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.4275 - acc: 0.7708\n",
      "Epoch 15/500\n",
      "288/288 [==============================] - 0s 138us/step - loss: 0.4309 - acc: 0.7951\n",
      "Epoch 16/500\n",
      "288/288 [==============================] - 0s 163us/step - loss: 0.4270 - acc: 0.7986\n",
      "Epoch 17/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.3951 - acc: 0.8021\n",
      "Epoch 18/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.4404 - acc: 0.7986\n",
      "Epoch 19/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3974 - acc: 0.7986\n",
      "Epoch 20/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.4044 - acc: 0.8125\n",
      "Epoch 21/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.4039 - acc: 0.7986\n",
      "Epoch 22/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.3810 - acc: 0.7951\n",
      "Epoch 23/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3638 - acc: 0.8229\n",
      "Epoch 24/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.4165 - acc: 0.7847\n",
      "Epoch 25/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.3868 - acc: 0.7882\n",
      "Epoch 26/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3733 - acc: 0.8333\n",
      "Epoch 27/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3652 - acc: 0.8299\n",
      "Epoch 28/500\n",
      "288/288 [==============================] - 0s 194us/step - loss: 0.4008 - acc: 0.8160\n",
      "Epoch 29/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3388 - acc: 0.8507\n",
      "Epoch 30/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.3717 - acc: 0.8333\n",
      "Epoch 31/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.3838 - acc: 0.8056\n",
      "Epoch 32/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3812 - acc: 0.8160\n",
      "Epoch 33/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.3600 - acc: 0.8368\n",
      "Epoch 34/500\n",
      "288/288 [==============================] - 0s 166us/step - loss: 0.3583 - acc: 0.8299\n",
      "Epoch 35/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3687 - acc: 0.8229\n",
      "Epoch 36/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.4210 - acc: 0.8264\n",
      "Epoch 37/500\n",
      "288/288 [==============================] - 0s 163us/step - loss: 0.3617 - acc: 0.8715\n",
      "Epoch 38/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.4060 - acc: 0.8125\n",
      "Epoch 39/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.4032 - acc: 0.8403\n",
      "Epoch 40/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3850 - acc: 0.8403\n",
      "Epoch 41/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.3719 - acc: 0.8229\n",
      "Epoch 42/500\n",
      "288/288 [==============================] - 0s 166us/step - loss: 0.3611 - acc: 0.8472\n",
      "Epoch 43/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.3769 - acc: 0.8125\n",
      "Epoch 44/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3840 - acc: 0.8056\n",
      "Epoch 45/500\n",
      "288/288 [==============================] - 0s 163us/step - loss: 0.3359 - acc: 0.8681\n",
      "Epoch 46/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3402 - acc: 0.8576\n",
      "Epoch 47/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.4196 - acc: 0.8090\n",
      "Epoch 48/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3469 - acc: 0.8333\n",
      "Epoch 49/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3684 - acc: 0.8646\n",
      "Epoch 50/500\n",
      "288/288 [==============================] - 0s 166us/step - loss: 0.3598 - acc: 0.8472\n",
      "Epoch 51/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3623 - acc: 0.8368\n",
      "Epoch 52/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.3585 - acc: 0.8681\n",
      "Epoch 53/500\n",
      "288/288 [==============================] - 0s 184us/step - loss: 0.3601 - acc: 0.8611\n",
      "Epoch 54/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.3961 - acc: 0.8368\n",
      "Epoch 55/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3499 - acc: 0.8194\n",
      "Epoch 56/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3590 - acc: 0.8437\n",
      "Epoch 57/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3510 - acc: 0.8437\n",
      "Epoch 58/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3543 - acc: 0.8681\n",
      "Epoch 59/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3683 - acc: 0.8125\n",
      "Epoch 60/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3655 - acc: 0.8542\n",
      "Epoch 61/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3180 - acc: 0.8472\n",
      "Epoch 62/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3561 - acc: 0.8472\n",
      "Epoch 63/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3672 - acc: 0.8437\n",
      "Epoch 64/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3335 - acc: 0.8368\n",
      "Epoch 65/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3151 - acc: 0.8750\n",
      "Epoch 66/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3476 - acc: 0.8889\n",
      "Epoch 67/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3178 - acc: 0.8750\n",
      "Epoch 68/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3567 - acc: 0.8681\n",
      "Epoch 69/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3167 - acc: 0.8785\n",
      "Epoch 70/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3385 - acc: 0.8542\n",
      "Epoch 71/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2908 - acc: 0.8958\n",
      "Epoch 72/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3408 - acc: 0.8368\n",
      "Epoch 73/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3222 - acc: 0.8646\n",
      "Epoch 74/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3755 - acc: 0.8542\n",
      "Epoch 75/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3514 - acc: 0.8681\n",
      "Epoch 76/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3756 - acc: 0.8368\n",
      "Epoch 77/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3485 - acc: 0.8750\n",
      "Epoch 78/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3433 - acc: 0.8437\n",
      "Epoch 79/500\n",
      "288/288 [==============================] - 0s 114us/step - loss: 0.3188 - acc: 0.8507\n",
      "Epoch 80/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3624 - acc: 0.8681\n",
      "Epoch 81/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3182 - acc: 0.8681\n",
      "Epoch 82/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3163 - acc: 0.8576\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 132us/step - loss: 0.3480 - acc: 0.8507\n",
      "Epoch 84/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.4131 - acc: 0.8299\n",
      "Epoch 85/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3653 - acc: 0.8542\n",
      "Epoch 86/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3634 - acc: 0.8646\n",
      "Epoch 87/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3684 - acc: 0.8681\n",
      "Epoch 88/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3093 - acc: 0.8576\n",
      "Epoch 89/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3677 - acc: 0.8472\n",
      "Epoch 90/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3921 - acc: 0.8437\n",
      "Epoch 91/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3490 - acc: 0.8750\n",
      "Epoch 92/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3238 - acc: 0.8646\n",
      "Epoch 93/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3214 - acc: 0.8542\n",
      "Epoch 94/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.4035 - acc: 0.8264\n",
      "Epoch 95/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3722 - acc: 0.8576\n",
      "Epoch 96/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3108 - acc: 0.8681\n",
      "Epoch 97/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3252 - acc: 0.8646\n",
      "Epoch 98/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3514 - acc: 0.8646\n",
      "Epoch 99/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3322 - acc: 0.8750\n",
      "Epoch 100/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3185 - acc: 0.8611\n",
      "Epoch 101/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3632 - acc: 0.8542\n",
      "Epoch 102/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3378 - acc: 0.8715\n",
      "Epoch 103/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3284 - acc: 0.8611\n",
      "Epoch 104/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3110 - acc: 0.8819\n",
      "Epoch 105/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.3447 - acc: 0.8785\n",
      "Epoch 106/500\n",
      "288/288 [==============================] - 0s 291us/step - loss: 0.3373 - acc: 0.8750\n",
      "Epoch 107/500\n",
      "288/288 [==============================] - 0s 336us/step - loss: 0.3276 - acc: 0.8750\n",
      "Epoch 108/500\n",
      "288/288 [==============================] - 0s 370us/step - loss: 0.3604 - acc: 0.8437\n",
      "Epoch 109/500\n",
      "288/288 [==============================] - 0s 253us/step - loss: 0.3202 - acc: 0.8611\n",
      "Epoch 110/500\n",
      "288/288 [==============================] - 0s 377us/step - loss: 0.3261 - acc: 0.8611 0s - loss: 0.3534 - acc: 0.840\n",
      "Epoch 111/500\n",
      "288/288 [==============================] - 0s 287us/step - loss: 0.2764 - acc: 0.9167\n",
      "Epoch 112/500\n",
      "288/288 [==============================] - 0s 232us/step - loss: 0.3066 - acc: 0.8750\n",
      "Epoch 113/500\n",
      "288/288 [==============================] - 0s 263us/step - loss: 0.3153 - acc: 0.8715\n",
      "Epoch 114/500\n",
      "288/288 [==============================] - 0s 284us/step - loss: 0.2912 - acc: 0.8924\n",
      "Epoch 115/500\n",
      "288/288 [==============================] - 0s 332us/step - loss: 0.3441 - acc: 0.8368\n",
      "Epoch 116/500\n",
      "288/288 [==============================] - 0s 308us/step - loss: 0.3105 - acc: 0.8611\n",
      "Epoch 117/500\n",
      "288/288 [==============================] - 0s 294us/step - loss: 0.3348 - acc: 0.8646\n",
      "Epoch 118/500\n",
      "288/288 [==============================] - 0s 183us/step - loss: 0.3469 - acc: 0.8507\n",
      "Epoch 119/500\n",
      "288/288 [==============================] - 0s 190us/step - loss: 0.3838 - acc: 0.8611\n",
      "Epoch 120/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3858 - acc: 0.8576\n",
      "Epoch 121/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3427 - acc: 0.8611\n",
      "Epoch 122/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2751 - acc: 0.8819\n",
      "Epoch 123/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3130 - acc: 0.8576\n",
      "Epoch 124/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3820 - acc: 0.8715\n",
      "Epoch 125/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3370 - acc: 0.8681\n",
      "Epoch 126/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.3423 - acc: 0.8611\n",
      "Epoch 127/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3448 - acc: 0.8785\n",
      "Epoch 128/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3107 - acc: 0.8715\n",
      "Epoch 129/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2927 - acc: 0.8785\n",
      "Epoch 130/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3361 - acc: 0.8819\n",
      "Epoch 131/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3629 - acc: 0.8507\n",
      "Epoch 132/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2958 - acc: 0.8715\n",
      "Epoch 133/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.3076 - acc: 0.8646\n",
      "Epoch 134/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3059 - acc: 0.8785\n",
      "Epoch 135/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.2976 - acc: 0.8854\n",
      "Epoch 136/500\n",
      "288/288 [==============================] - 0s 170us/step - loss: 0.3360 - acc: 0.8785\n",
      "Epoch 137/500\n",
      "288/288 [==============================] - 0s 291us/step - loss: 0.3210 - acc: 0.8611\n",
      "Epoch 138/500\n",
      "288/288 [==============================] - 0s 222us/step - loss: 0.3322 - acc: 0.8958\n",
      "Epoch 139/500\n",
      "288/288 [==============================] - 0s 197us/step - loss: 0.3271 - acc: 0.8542\n",
      "Epoch 140/500\n",
      "288/288 [==============================] - ETA: 0s - loss: 0.6355 - acc: 0.700 - 0s 166us/step - loss: 0.3171 - acc: 0.8576\n",
      "Epoch 141/500\n",
      "288/288 [==============================] - 0s 253us/step - loss: 0.3441 - acc: 0.8750\n",
      "Epoch 142/500\n",
      "288/288 [==============================] - 0s 194us/step - loss: 0.3086 - acc: 0.8924\n",
      "Epoch 143/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.3094 - acc: 0.8785\n",
      "Epoch 144/500\n",
      "288/288 [==============================] - 0s 235us/step - loss: 0.3289 - acc: 0.8715\n",
      "Epoch 145/500\n",
      "288/288 [==============================] - 0s 291us/step - loss: 0.3356 - acc: 0.8403\n",
      "Epoch 146/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.2846 - acc: 0.9132\n",
      "Epoch 147/500\n",
      "288/288 [==============================] - 0s 211us/step - loss: 0.3407 - acc: 0.8715\n",
      "Epoch 148/500\n",
      "288/288 [==============================] - 0s 190us/step - loss: 0.3117 - acc: 0.8576\n",
      "Epoch 149/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.2730 - acc: 0.9028\n",
      "Epoch 150/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.3278 - acc: 0.8507\n",
      "Epoch 151/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.2675 - acc: 0.8993\n",
      "Epoch 152/500\n",
      "288/288 [==============================] - 0s 180us/step - loss: 0.3286 - acc: 0.8715\n",
      "Epoch 153/500\n",
      "288/288 [==============================] - 0s 180us/step - loss: 0.3166 - acc: 0.8889\n",
      "Epoch 154/500\n",
      "288/288 [==============================] - 0s 270us/step - loss: 0.2863 - acc: 0.8889\n",
      "Epoch 155/500\n",
      "288/288 [==============================] - 0s 166us/step - loss: 0.3288 - acc: 0.8750\n",
      "Epoch 156/500\n",
      "288/288 [==============================] - 0s 180us/step - loss: 0.3131 - acc: 0.8507\n",
      "Epoch 157/500\n",
      "288/288 [==============================] - 0s 180us/step - loss: 0.2794 - acc: 0.9167\n",
      "Epoch 158/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.3296 - acc: 0.8785\n",
      "Epoch 159/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3051 - acc: 0.8646\n",
      "Epoch 160/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2606 - acc: 0.8958\n",
      "Epoch 161/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2938 - acc: 0.8750\n",
      "Epoch 162/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3391 - acc: 0.8646\n",
      "Epoch 163/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3371 - acc: 0.8646\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 128us/step - loss: 0.2994 - acc: 0.8889\n",
      "Epoch 165/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2863 - acc: 0.8889\n",
      "Epoch 166/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2694 - acc: 0.8924\n",
      "Epoch 167/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3614 - acc: 0.8403\n",
      "Epoch 168/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2961 - acc: 0.8750\n",
      "Epoch 169/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3716 - acc: 0.8299\n",
      "Epoch 170/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3449 - acc: 0.8785\n",
      "Epoch 171/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2754 - acc: 0.8715\n",
      "Epoch 172/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3035 - acc: 0.8646\n",
      "Epoch 173/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3233 - acc: 0.8750\n",
      "Epoch 174/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2750 - acc: 0.8750\n",
      "Epoch 175/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3113 - acc: 0.8611\n",
      "Epoch 176/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2454 - acc: 0.9062\n",
      "Epoch 177/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3406 - acc: 0.8576\n",
      "Epoch 178/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3024 - acc: 0.8819\n",
      "Epoch 179/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2629 - acc: 0.9132\n",
      "Epoch 180/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2926 - acc: 0.8819\n",
      "Epoch 181/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2446 - acc: 0.9028\n",
      "Epoch 182/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2953 - acc: 0.8854\n",
      "Epoch 183/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3208 - acc: 0.8437\n",
      "Epoch 184/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2795 - acc: 0.8750\n",
      "Epoch 185/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3058 - acc: 0.8750\n",
      "Epoch 186/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2401 - acc: 0.8819\n",
      "Epoch 187/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3316 - acc: 0.8611\n",
      "Epoch 188/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2955 - acc: 0.8750\n",
      "Epoch 189/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3671 - acc: 0.8403\n",
      "Epoch 190/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3521 - acc: 0.8472\n",
      "Epoch 191/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3586 - acc: 0.8542\n",
      "Epoch 192/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3147 - acc: 0.8681\n",
      "Epoch 193/500\n",
      "288/288 [==============================] - 0s 170us/step - loss: 0.3281 - acc: 0.8646\n",
      "Epoch 194/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.3739 - acc: 0.8576\n",
      "Epoch 195/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.2812 - acc: 0.8819\n",
      "Epoch 196/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3007 - acc: 0.8750\n",
      "Epoch 197/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3048 - acc: 0.8646\n",
      "Epoch 198/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3354 - acc: 0.8542\n",
      "Epoch 199/500\n",
      "288/288 [==============================] - 0s 201us/step - loss: 0.3267 - acc: 0.8611\n",
      "Epoch 200/500\n",
      "288/288 [==============================] - 0s 232us/step - loss: 0.3383 - acc: 0.8646\n",
      "Epoch 201/500\n",
      "288/288 [==============================] - 0s 274us/step - loss: 0.3158 - acc: 0.8715\n",
      "Epoch 202/500\n",
      "288/288 [==============================] - 0s 222us/step - loss: 0.3341 - acc: 0.8715\n",
      "Epoch 203/500\n",
      "288/288 [==============================] - 0s 242us/step - loss: 0.3450 - acc: 0.8542\n",
      "Epoch 204/500\n",
      "288/288 [==============================] - 0s 201us/step - loss: 0.3429 - acc: 0.8785\n",
      "Epoch 205/500\n",
      "288/288 [==============================] - 0s 253us/step - loss: 0.3058 - acc: 0.8715\n",
      "Epoch 206/500\n",
      "288/288 [==============================] - 0s 187us/step - loss: 0.2903 - acc: 0.8924\n",
      "Epoch 207/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2608 - acc: 0.8958\n",
      "Epoch 208/500\n",
      "288/288 [==============================] - 0s 184us/step - loss: 0.2693 - acc: 0.8819\n",
      "Epoch 209/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.2583 - acc: 0.8889\n",
      "Epoch 210/500\n",
      "288/288 [==============================] - 0s 208us/step - loss: 0.3248 - acc: 0.8750\n",
      "Epoch 211/500\n",
      "288/288 [==============================] - 0s 336us/step - loss: 0.3470 - acc: 0.8472\n",
      "Epoch 212/500\n",
      "288/288 [==============================] - 0s 315us/step - loss: 0.2852 - acc: 0.8889\n",
      "Epoch 213/500\n",
      "288/288 [==============================] - 0s 208us/step - loss: 0.3890 - acc: 0.8611\n",
      "Epoch 214/500\n",
      "288/288 [==============================] - 0s 177us/step - loss: 0.2961 - acc: 0.8854\n",
      "Epoch 215/500\n",
      "288/288 [==============================] - 0s 232us/step - loss: 0.2982 - acc: 0.8785\n",
      "Epoch 216/500\n",
      "288/288 [==============================] - 0s 173us/step - loss: 0.3911 - acc: 0.8333\n",
      "Epoch 217/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3554 - acc: 0.8854\n",
      "Epoch 218/500\n",
      "288/288 [==============================] - 0s 173us/step - loss: 0.3180 - acc: 0.8715\n",
      "Epoch 219/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3333 - acc: 0.8924\n",
      "Epoch 220/500\n",
      "288/288 [==============================] - 0s 173us/step - loss: 0.3103 - acc: 0.8715\n",
      "Epoch 221/500\n",
      "288/288 [==============================] - 0s 197us/step - loss: 0.3312 - acc: 0.8681\n",
      "Epoch 222/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.2826 - acc: 0.8819\n",
      "Epoch 223/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3097 - acc: 0.8785\n",
      "Epoch 224/500\n",
      "288/288 [==============================] - 0s 163us/step - loss: 0.3514 - acc: 0.8472\n",
      "Epoch 225/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.2929 - acc: 0.8854\n",
      "Epoch 226/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3095 - acc: 0.8889\n",
      "Epoch 227/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.2909 - acc: 0.8958\n",
      "Epoch 228/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3183 - acc: 0.8681\n",
      "Epoch 229/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3458 - acc: 0.8993\n",
      "Epoch 230/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3059 - acc: 0.8993\n",
      "Epoch 231/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3069 - acc: 0.8681\n",
      "Epoch 232/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.2914 - acc: 0.8924\n",
      "Epoch 233/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3028 - acc: 0.8715\n",
      "Epoch 234/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2750 - acc: 0.8889\n",
      "Epoch 235/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3233 - acc: 0.8681\n",
      "Epoch 236/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2866 - acc: 0.8819\n",
      "Epoch 237/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2905 - acc: 0.8576\n",
      "Epoch 238/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3014 - acc: 0.8646\n",
      "Epoch 239/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.2648 - acc: 0.9028\n",
      "Epoch 240/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3235 - acc: 0.8715\n",
      "Epoch 241/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3089 - acc: 0.8819\n",
      "Epoch 242/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3425 - acc: 0.8785\n",
      "Epoch 243/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3163 - acc: 0.8681\n",
      "Epoch 244/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3281 - acc: 0.8715\n",
      "Epoch 245/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.2473 - acc: 0.8889\n",
      "Epoch 246/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 139us/step - loss: 0.3169 - acc: 0.8646\n",
      "Epoch 247/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.2763 - acc: 0.8854\n",
      "Epoch 248/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.2584 - acc: 0.9028\n",
      "Epoch 249/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2790 - acc: 0.8993\n",
      "Epoch 250/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3191 - acc: 0.8472\n",
      "Epoch 251/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3191 - acc: 0.8854\n",
      "Epoch 252/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.2970 - acc: 0.8750\n",
      "Epoch 253/500\n",
      "288/288 [==============================] - 0s 156us/step - loss: 0.2364 - acc: 0.9167\n",
      "Epoch 254/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.2854 - acc: 0.8889\n",
      "Epoch 255/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3453 - acc: 0.8715\n",
      "Epoch 256/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2500 - acc: 0.9167\n",
      "Epoch 257/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.2649 - acc: 0.8993\n",
      "Epoch 258/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2523 - acc: 0.8750\n",
      "Epoch 259/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2655 - acc: 0.8993\n",
      "Epoch 260/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.2759 - acc: 0.8993\n",
      "Epoch 261/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2869 - acc: 0.9062\n",
      "Epoch 262/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3034 - acc: 0.8854\n",
      "Epoch 263/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3391 - acc: 0.8646\n",
      "Epoch 264/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3533 - acc: 0.8785\n",
      "Epoch 265/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2738 - acc: 0.9028\n",
      "Epoch 266/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3259 - acc: 0.8611\n",
      "Epoch 267/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3084 - acc: 0.8611\n",
      "Epoch 268/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2901 - acc: 0.8750\n",
      "Epoch 269/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2703 - acc: 0.9028\n",
      "Epoch 270/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.2803 - acc: 0.8819\n",
      "Epoch 271/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3205 - acc: 0.8715\n",
      "Epoch 272/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3105 - acc: 0.8681\n",
      "Epoch 273/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2556 - acc: 0.9097\n",
      "Epoch 274/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2829 - acc: 0.8889\n",
      "Epoch 275/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3233 - acc: 0.8785\n",
      "Epoch 276/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3129 - acc: 0.8785\n",
      "Epoch 277/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3117 - acc: 0.8785\n",
      "Epoch 278/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3080 - acc: 0.8681\n",
      "Epoch 279/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2492 - acc: 0.9132\n",
      "Epoch 280/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3302 - acc: 0.8750\n",
      "Epoch 281/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3125 - acc: 0.8681\n",
      "Epoch 282/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2938 - acc: 0.8785\n",
      "Epoch 283/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3030 - acc: 0.8785\n",
      "Epoch 284/500\n",
      "288/288 [==============================] - 0s 114us/step - loss: 0.2707 - acc: 0.8993\n",
      "Epoch 285/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3501 - acc: 0.8542\n",
      "Epoch 286/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3506 - acc: 0.8576\n",
      "Epoch 287/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2517 - acc: 0.9097\n",
      "Epoch 288/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2579 - acc: 0.9132\n",
      "Epoch 289/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2937 - acc: 0.8681\n",
      "Epoch 290/500\n",
      "288/288 [==============================] - 0s 138us/step - loss: 0.3613 - acc: 0.8437\n",
      "Epoch 291/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3433 - acc: 0.8819\n",
      "Epoch 292/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2615 - acc: 0.9167\n",
      "Epoch 293/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3362 - acc: 0.8646\n",
      "Epoch 294/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2590 - acc: 0.8889\n",
      "Epoch 295/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3013 - acc: 0.8750\n",
      "Epoch 296/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3499 - acc: 0.8750\n",
      "Epoch 297/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.2646 - acc: 0.8819\n",
      "Epoch 298/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3251 - acc: 0.8785\n",
      "Epoch 299/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.4004 - acc: 0.8542\n",
      "Epoch 300/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2814 - acc: 0.9028\n",
      "Epoch 301/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3375 - acc: 0.8576\n",
      "Epoch 302/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2928 - acc: 0.8958\n",
      "Epoch 303/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3030 - acc: 0.8681\n",
      "Epoch 304/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2850 - acc: 0.8924\n",
      "Epoch 305/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2783 - acc: 0.8785\n",
      "Epoch 306/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3276 - acc: 0.8437\n",
      "Epoch 307/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3348 - acc: 0.8681\n",
      "Epoch 308/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3121 - acc: 0.8542\n",
      "Epoch 309/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3060 - acc: 0.9062\n",
      "Epoch 310/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2954 - acc: 0.8611\n",
      "Epoch 311/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2885 - acc: 0.8819\n",
      "Epoch 312/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.3054 - acc: 0.8889\n",
      "Epoch 313/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3107 - acc: 0.8889\n",
      "Epoch 314/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3298 - acc: 0.8819\n",
      "Epoch 315/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3788 - acc: 0.8507\n",
      "Epoch 316/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2609 - acc: 0.9028\n",
      "Epoch 317/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3394 - acc: 0.8681\n",
      "Epoch 318/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3179 - acc: 0.8785\n",
      "Epoch 319/500\n",
      "288/288 [==============================] - 0s 111us/step - loss: 0.3213 - acc: 0.8785\n",
      "Epoch 320/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2632 - acc: 0.8889\n",
      "Epoch 321/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2739 - acc: 0.8924\n",
      "Epoch 322/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3200 - acc: 0.8785\n",
      "Epoch 323/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3074 - acc: 0.8958\n",
      "Epoch 324/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2785 - acc: 0.8785\n",
      "Epoch 325/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2945 - acc: 0.8785\n",
      "Epoch 326/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3292 - acc: 0.8854\n",
      "Epoch 327/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3013 - acc: 0.8854\n",
      "Epoch 328/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 139us/step - loss: 0.2879 - acc: 0.8958\n",
      "Epoch 329/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2840 - acc: 0.9097\n",
      "Epoch 330/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3315 - acc: 0.8646\n",
      "Epoch 331/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2554 - acc: 0.9097\n",
      "Epoch 332/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2659 - acc: 0.8958\n",
      "Epoch 333/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2770 - acc: 0.9062\n",
      "Epoch 334/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3116 - acc: 0.8750\n",
      "Epoch 335/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3036 - acc: 0.8854\n",
      "Epoch 336/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3047 - acc: 0.8819\n",
      "Epoch 337/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2959 - acc: 0.8750\n",
      "Epoch 338/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2627 - acc: 0.9132\n",
      "Epoch 339/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2756 - acc: 0.8715\n",
      "Epoch 340/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3172 - acc: 0.8646\n",
      "Epoch 341/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2935 - acc: 0.8576\n",
      "Epoch 342/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3166 - acc: 0.8646\n",
      "Epoch 343/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2697 - acc: 0.9028\n",
      "Epoch 344/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3277 - acc: 0.8785\n",
      "Epoch 345/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2981 - acc: 0.8715\n",
      "Epoch 346/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.3011 - acc: 0.8750\n",
      "Epoch 347/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2716 - acc: 0.9028\n",
      "Epoch 348/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3023 - acc: 0.8750\n",
      "Epoch 349/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3045 - acc: 0.8819\n",
      "Epoch 350/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3085 - acc: 0.8750\n",
      "Epoch 351/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3023 - acc: 0.8819\n",
      "Epoch 352/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3244 - acc: 0.8576\n",
      "Epoch 353/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2397 - acc: 0.9028\n",
      "Epoch 354/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2846 - acc: 0.8889\n",
      "Epoch 355/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3355 - acc: 0.8750\n",
      "Epoch 356/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3008 - acc: 0.8785\n",
      "Epoch 357/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2985 - acc: 0.8889\n",
      "Epoch 358/500\n",
      "288/288 [==============================] - 0s 111us/step - loss: 0.3303 - acc: 0.8715\n",
      "Epoch 359/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3293 - acc: 0.8542\n",
      "Epoch 360/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2583 - acc: 0.8958\n",
      "Epoch 361/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2825 - acc: 0.8889\n",
      "Epoch 362/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2985 - acc: 0.8715\n",
      "Epoch 363/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3773 - acc: 0.8785\n",
      "Epoch 364/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2693 - acc: 0.8924\n",
      "Epoch 365/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2836 - acc: 0.9028\n",
      "Epoch 366/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2861 - acc: 0.8889\n",
      "Epoch 367/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3165 - acc: 0.8646\n",
      "Epoch 368/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2420 - acc: 0.8854\n",
      "Epoch 369/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3596 - acc: 0.8542\n",
      "Epoch 370/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2919 - acc: 0.8681\n",
      "Epoch 371/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2755 - acc: 0.8785\n",
      "Epoch 372/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2702 - acc: 0.9028\n",
      "Epoch 373/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3269 - acc: 0.9028\n",
      "Epoch 374/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3106 - acc: 0.8715\n",
      "Epoch 375/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2860 - acc: 0.9097\n",
      "Epoch 376/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2902 - acc: 0.8993\n",
      "Epoch 377/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2967 - acc: 0.8854\n",
      "Epoch 378/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2964 - acc: 0.8819\n",
      "Epoch 379/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2433 - acc: 0.8924\n",
      "Epoch 380/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2834 - acc: 0.8715\n",
      "Epoch 381/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.2797 - acc: 0.8681\n",
      "Epoch 382/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2593 - acc: 0.8889\n",
      "Epoch 383/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2833 - acc: 0.8750\n",
      "Epoch 384/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3136 - acc: 0.8681\n",
      "Epoch 385/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2951 - acc: 0.8681\n",
      "Epoch 386/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2985 - acc: 0.8854\n",
      "Epoch 387/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3552 - acc: 0.8472\n",
      "Epoch 388/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3120 - acc: 0.8819\n",
      "Epoch 389/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.3638 - acc: 0.8750\n",
      "Epoch 390/500\n",
      "288/288 [==============================] - 0s 249us/step - loss: 0.3414 - acc: 0.8715\n",
      "Epoch 391/500\n",
      "288/288 [==============================] - 0s 204us/step - loss: 0.2829 - acc: 0.8958\n",
      "Epoch 392/500\n",
      "288/288 [==============================] - 0s 239us/step - loss: 0.2437 - acc: 0.9028\n",
      "Epoch 393/500\n",
      "288/288 [==============================] - 0s 190us/step - loss: 0.3223 - acc: 0.8611\n",
      "Epoch 394/500\n",
      "288/288 [==============================] - 0s 173us/step - loss: 0.3541 - acc: 0.8785\n",
      "Epoch 395/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.3143 - acc: 0.8542\n",
      "Epoch 396/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2675 - acc: 0.9028\n",
      "Epoch 397/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3377 - acc: 0.8681\n",
      "Epoch 398/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3516 - acc: 0.8785\n",
      "Epoch 399/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.3031 - acc: 0.8542\n",
      "Epoch 400/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2637 - acc: 0.8819\n",
      "Epoch 401/500\n",
      "288/288 [==============================] - 0s 149us/step - loss: 0.3056 - acc: 0.8785\n",
      "Epoch 402/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3282 - acc: 0.8819\n",
      "Epoch 403/500\n",
      "288/288 [==============================] - 0s 142us/step - loss: 0.2797 - acc: 0.8958\n",
      "Epoch 404/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.3141 - acc: 0.8819\n",
      "Epoch 405/500\n",
      "288/288 [==============================] - 0s 197us/step - loss: 0.3346 - acc: 0.8715\n",
      "Epoch 406/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.2623 - acc: 0.8958\n",
      "Epoch 407/500\n",
      "288/288 [==============================] - 0s 163us/step - loss: 0.3173 - acc: 0.8854\n",
      "Epoch 408/500\n",
      "288/288 [==============================] - 0s 197us/step - loss: 0.3084 - acc: 0.8611\n",
      "Epoch 409/500\n",
      "288/288 [==============================] - 0s 166us/step - loss: 0.3271 - acc: 0.8785\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 170us/step - loss: 0.2784 - acc: 0.8889\n",
      "Epoch 411/500\n",
      "288/288 [==============================] - 0s 159us/step - loss: 0.3216 - acc: 0.8681\n",
      "Epoch 412/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3199 - acc: 0.8889\n",
      "Epoch 413/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3062 - acc: 0.8750\n",
      "Epoch 414/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2965 - acc: 0.9097\n",
      "Epoch 415/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3269 - acc: 0.8750\n",
      "Epoch 416/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3059 - acc: 0.8542\n",
      "Epoch 417/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3594 - acc: 0.8472\n",
      "Epoch 418/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2849 - acc: 0.8854\n",
      "Epoch 419/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2611 - acc: 0.8958\n",
      "Epoch 420/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3037 - acc: 0.8854\n",
      "Epoch 421/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3120 - acc: 0.8819\n",
      "Epoch 422/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2795 - acc: 0.8889\n",
      "Epoch 423/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3149 - acc: 0.8681\n",
      "Epoch 424/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2791 - acc: 0.8819\n",
      "Epoch 425/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3138 - acc: 0.8576\n",
      "Epoch 426/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2556 - acc: 0.9028\n",
      "Epoch 427/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2690 - acc: 0.9028\n",
      "Epoch 428/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2761 - acc: 0.8924\n",
      "Epoch 429/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2803 - acc: 0.8924\n",
      "Epoch 430/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2890 - acc: 0.8889\n",
      "Epoch 431/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2670 - acc: 0.8993\n",
      "Epoch 432/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3015 - acc: 0.8715\n",
      "Epoch 433/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2904 - acc: 0.8819\n",
      "Epoch 434/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2879 - acc: 0.8854\n",
      "Epoch 435/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3414 - acc: 0.8646\n",
      "Epoch 436/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3203 - acc: 0.8750\n",
      "Epoch 437/500\n",
      "288/288 [==============================] - 0s 145us/step - loss: 0.3943 - acc: 0.8889\n",
      "Epoch 438/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2969 - acc: 0.8958\n",
      "Epoch 439/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3016 - acc: 0.8576\n",
      "Epoch 440/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2954 - acc: 0.8819\n",
      "Epoch 441/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3385 - acc: 0.8611\n",
      "Epoch 442/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2850 - acc: 0.8750\n",
      "Epoch 443/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3160 - acc: 0.8611\n",
      "Epoch 444/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2807 - acc: 0.8889\n",
      "Epoch 445/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2976 - acc: 0.8681\n",
      "Epoch 446/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.3266 - acc: 0.8750\n",
      "Epoch 447/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3446 - acc: 0.8646\n",
      "Epoch 448/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3149 - acc: 0.8785\n",
      "Epoch 449/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2897 - acc: 0.8958\n",
      "Epoch 450/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2822 - acc: 0.8785\n",
      "Epoch 451/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2416 - acc: 0.9167\n",
      "Epoch 452/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3191 - acc: 0.8437\n",
      "Epoch 453/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2924 - acc: 0.8854\n",
      "Epoch 454/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2517 - acc: 0.8958\n",
      "Epoch 455/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3072 - acc: 0.8819\n",
      "Epoch 456/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2589 - acc: 0.8819\n",
      "Epoch 457/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3252 - acc: 0.8750\n",
      "Epoch 458/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.2861 - acc: 0.8819\n",
      "Epoch 459/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2602 - acc: 0.8819\n",
      "Epoch 460/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2806 - acc: 0.9132\n",
      "Epoch 461/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3062 - acc: 0.8819\n",
      "Epoch 462/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3223 - acc: 0.8819\n",
      "Epoch 463/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2891 - acc: 0.8785\n",
      "Epoch 464/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2598 - acc: 0.9132\n",
      "Epoch 465/500\n",
      "288/288 [==============================] - 0s 139us/step - loss: 0.2908 - acc: 0.8924\n",
      "Epoch 466/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3535 - acc: 0.8646\n",
      "Epoch 467/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2954 - acc: 0.8646\n",
      "Epoch 468/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.2729 - acc: 0.8854\n",
      "Epoch 469/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3183 - acc: 0.8750\n",
      "Epoch 470/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2697 - acc: 0.8924\n",
      "Epoch 471/500\n",
      "288/288 [==============================] - 0s 111us/step - loss: 0.3006 - acc: 0.8889\n",
      "Epoch 472/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2993 - acc: 0.8611\n",
      "Epoch 473/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.2998 - acc: 0.8785\n",
      "Epoch 474/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.3272 - acc: 0.8507\n",
      "Epoch 475/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2506 - acc: 0.8993\n",
      "Epoch 476/500\n",
      "288/288 [==============================] - 0s 118us/step - loss: 0.2348 - acc: 0.9167\n",
      "Epoch 477/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2816 - acc: 0.8924\n",
      "Epoch 478/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3030 - acc: 0.8854\n",
      "Epoch 479/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3377 - acc: 0.8681\n",
      "Epoch 480/500\n",
      "288/288 [==============================] - 0s 114us/step - loss: 0.2789 - acc: 0.8958\n",
      "Epoch 481/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2573 - acc: 0.8924\n",
      "Epoch 482/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3013 - acc: 0.8854\n",
      "Epoch 483/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2743 - acc: 0.8889\n",
      "Epoch 484/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.3151 - acc: 0.8611\n",
      "Epoch 485/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2893 - acc: 0.8993\n",
      "Epoch 486/500\n",
      "288/288 [==============================] - 0s 125us/step - loss: 0.2808 - acc: 0.8924\n",
      "Epoch 487/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.3015 - acc: 0.8785\n",
      "Epoch 488/500\n",
      "288/288 [==============================] - 0s 121us/step - loss: 0.3028 - acc: 0.8681\n",
      "Epoch 489/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3416 - acc: 0.8889\n",
      "Epoch 490/500\n",
      "288/288 [==============================] - 0s 128us/step - loss: 0.2974 - acc: 0.8646\n",
      "Epoch 491/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2828 - acc: 0.8854\n",
      "Epoch 492/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288/288 [==============================] - 0s 121us/step - loss: 0.2977 - acc: 0.8819\n",
      "Epoch 493/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3014 - acc: 0.8819\n",
      "Epoch 494/500\n",
      "288/288 [==============================] - 0s 132us/step - loss: 0.2880 - acc: 0.8993\n",
      "Epoch 495/500\n",
      "288/288 [==============================] - 0s 135us/step - loss: 0.3608 - acc: 0.8472\n",
      "Epoch 496/500\n",
      "288/288 [==============================] - 0s 152us/step - loss: 0.2747 - acc: 0.8819\n",
      "Epoch 497/500\n",
      "288/288 [==============================] - 0s 246us/step - loss: 0.2717 - acc: 0.8819\n",
      "Epoch 498/500\n",
      "288/288 [==============================] - 0s 294us/step - loss: 0.3405 - acc: 0.8507\n",
      "Epoch 499/500\n",
      "288/288 [==============================] - 0s 253us/step - loss: 0.2760 - acc: 0.9028\n",
      "Epoch 500/500\n",
      "288/288 [==============================] - 0s 315us/step - loss: 0.3056 - acc: 0.8819\n"
     ]
    }
   ],
   "source": [
    "# compile, fit and predict \n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "classifier.fit(X, y, batch_size=10, epochs=500)\n",
    "y_pred = classifier.predict(X)\n",
    "y_pred = (y_pred > 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use 500 epochs with batch size of 10 to train ANN model. Since we are more concerned about identifying sick people rather than misclassifying a healthy person, I slighly reduce the threshold to 0.4 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2e72ddf65f8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score\n",
    "import seaborn as sn\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize = (7,5))\n",
    "plt.title('Confusion Matrix')\n",
    "sn.heatmap(cm, annot=True, cmap='Greens', fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix is a comparison of true lables vs predicted labels. Since we have kept the prediction threshold to be 0.4, we see that there is one false positive while rest of the predictions are correct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# recall -\n",
    "recall = recall_score(y, y_pred)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are more concerned about false negatives (categorizing sick person as healthy) than false positives (categorizing healthy person as sick), recall is a good indicator of how well we perform in this scenario. Recall score was 1.0 when I ran for the last time. Essentially, there were no false negatives. \n",
    "Since we have taken care of overfitting through regularization, we assume prediction is stable across datasets i.e low variance. A test set could have helped me in this regard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# roc curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y, y_pred)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.figure(2)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.2,1.2])\n",
    "plt.ylim([-0.2,1.2])\n",
    "plt.ylabel(' True Positive Rate')\n",
    "plt.xlabel(' False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receiver operating characteristic (ROC) is used to visualize the performance of a binary classifier. It helps to select model independent of the class distribution (Fig.1). We can see that our model has the best possible performance in ROC curve. Dotted line denotes random classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, We have to take this result with a pinch of salt. There is a high possibility of overfitting since dataset is really small. We could enhance the perrformance of this classifier by increasing dataset, providing a test/validation set or by cross validation etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
